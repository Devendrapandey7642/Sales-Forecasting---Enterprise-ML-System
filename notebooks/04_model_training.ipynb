{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9077692e",
   "metadata": {},
   "source": [
    "# 04 - Model Training\n",
    "\n",
    "Train multiple ML/DL models for sales forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sys.path.append('../src')\n",
    "from train import train_model, save_model\n",
    "from evaluate import calculate_metrics, print_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df3bde",
   "metadata": {},
   "source": [
    "## Load Featured Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/featured_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bba6d",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target_col = 'quantity'  # Target variable for sales forecasting\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a6790",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24537e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test size: {X_test.shape[0]} samples\")\n",
    "print(f\"Training ratio: {X_train.shape[0] / len(df) * 100:.1f}%\")\n",
    "print(f\"Test ratio: {X_test.shape[0] / len(df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9942a83",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb95a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úì Features scaled\")\n",
    "print(f\"Train mean: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Train std: {X_train_scaled.std():.6f}\")\n",
    "\n",
    "# Save scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"‚úì Scaler saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95a782",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef916200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {}\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "print(\"1. Linear Regression...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "models['linear_regression'] = lr_model\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "print_metrics(calculate_metrics(y_test, y_pred_lr))\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"\\n2. Random Forest Regressor...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "models['random_forest'] = rf_model\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "print_metrics(calculate_metrics(y_test, y_pred_rf))\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "print(\"\\n3. Gradient Boosting Regressor...\")\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "models['gradient_boosting'] = gb_model\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "print_metrics(calculate_metrics(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8cbbe",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6671ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    results[name] = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "best_model_name = results_df['R2'].idxmax()\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "best_model = models[best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c921ff3",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1651e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = '../models/best_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f\"‚úì Best model saved: {model_path}\")\n",
    "print(f\"  Model type: {type(best_model).__name__}\")\n",
    "print(f\"  R¬≤ Score: {results_df.loc[best_model_name, 'R2']:.4f}\")\n",
    "print(f\"  RMSE: {results_df.loc[best_model_name, 'RMSE']:.4f}\")\n",
    "print(f\"  MAE: {results_df.loc[best_model_name, 'MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae840de",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e91293",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Important Features:\")\n",
    "    print(feature_importance_df.head(10))\n",
    "    \n",
    "    # Plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    feature_importance_df.head(10).plot(x='feature', y='importance', kind='barh', ax=ax)\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/feature_importance.png', dpi=100)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Selected model does not have feature importances\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
