{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b171f8e",
   "metadata": {},
   "source": [
    "# 05 - Model Evaluation\n",
    "\n",
    "Comprehensive model evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683eab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src.evaluate import calculate_metrics, print_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250a251",
   "metadata": {},
   "source": [
    "## Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ce36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/processed/featured_dataset.csv')\n",
    "\n",
    "# Load best model and scaler\n",
    "with open('../models/best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "with open('../models/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Model loaded: {type(best_model).__name__}\")\n",
    "print(f\"✓ Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ab53b",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'quantity'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Use same split as training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Test period: index {X_test.index[0]} to {X_test.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7489e",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"✓ Predictions generated\")\n",
    "print(f\"  Min prediction: {y_pred.min():.2f}\")\n",
    "print(f\"  Max prediction: {y_pred.max():.2f}\")\n",
    "print(f\"  Mean prediction: {y_pred.mean():.2f}\")\n",
    "print(f\"\\n  Min actual: {y_test.min():.2f}\")\n",
    "print(f\"  Max actual: {y_test.max():.2f}\")\n",
    "print(f\"  Mean actual: {y_test.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0cddb3",
   "metadata": {},
   "source": [
    "## Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c04e3",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test.values - y_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Residuals over time\n",
    "axes[0, 0].plot(residuals)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_title('Residuals Over Time')\n",
    "axes[0, 0].set_ylabel('Residual')\n",
    "\n",
    "# 2. Histogram of residuals\n",
    "axes[0, 1].hist(residuals, bins=50, edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution of Residuals')\n",
    "axes[0, 1].set_xlabel('Residual')\n",
    "\n",
    "# 3. Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot')\n",
    "\n",
    "# 4. Predicted vs Actual\n",
    "axes[1, 1].scatter(y_test, y_pred, alpha=0.5)\n",
    "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 1].set_xlabel('Actual')\n",
    "axes[1, 1].set_ylabel('Predicted')\n",
    "axes[1, 1].set_title('Predicted vs Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/model_evaluation.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d806a",
   "metadata": {},
   "source": [
    "## Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute percentage error\n",
    "mape_values = np.abs((y_test.values - y_pred) / y_test.values) * 100\n",
    "\n",
    "print(\"Error Metrics:\")\n",
    "print(f\"  Mean Absolute Percentage Error (MAPE): {mape_values.mean():.2f}%\")\n",
    "print(f\"  Median Absolute Percentage Error: {np.median(mape_values):.2f}%\")\n",
    "print(f\"  95th Percentile Error: {np.percentile(mape_values, 95):.2f}%\")\n",
    "print(f\"  Max Absolute Error: {np.max(np.abs(residuals)):.2f}\")\n",
    "\n",
    "# Plot error distribution\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=mape_values,\n",
    "    nbinsx=50,\n",
    "    name='MAPE Distribution'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title='Distribution of Absolute Percentage Error (MAPE)',\n",
    "    xaxis_title='MAPE (%)',\n",
    "    yaxis_title='Frequency'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c538af",
   "metadata": {},
   "source": [
    "## Forecast Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c804875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive plot of predictions\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=y_test.values,\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Add predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=y_pred,\n",
    "    mode='lines',\n",
    "    name='Predicted',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Sales',\n",
    "    xaxis_title='Sample Index',\n",
    "    yaxis_title='Sales',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c61e4",
   "metadata": {},
   "source": [
    "## Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94160a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Metric': ['R² Score', 'RMSE', 'MAE', 'MAPE', 'Mean Residual', 'Std Residual'],\n",
    "    'Value': [\n",
    "        f\"{metrics['R2']:.4f}\",\n",
    "        f\"{metrics['RMSE']:.4f}\",\n",
    "        f\"{metrics['MAE']:.4f}\",\n",
    "        f\"{metrics['MAPE']:.2f}%\",\n",
    "        f\"{residuals.mean():.4f}\",\n",
    "        f\"{residuals.std():.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67ff88",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "results_df = pd.DataFrame({\n",
    "    'index': y_test.index,\n",
    "    'actual': y_test.values,\n",
    "    'predicted': y_pred,\n",
    "    'residual': residuals,\n",
    "    'abs_error': np.abs(residuals),\n",
    "    'mape': mape_values\n",
    "})\n",
    "\n",
    "results_df.to_csv('../reports/prediction_results.csv', index=False)\n",
    "print(f\"✓ Predictions saved to: ../reports/prediction_results.csv\")\n",
    "print(f\"\\nSample results:\")\n",
    "print(results_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
