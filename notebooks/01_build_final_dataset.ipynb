{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec2010b",
   "metadata": {},
   "source": [
    "# 01 - Build Final Dataset\n",
    "\n",
    "Merge all raw CSV files into one master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src.data_pipeline import load_raw_data, merge_datasets, handle_missing_values, build_final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6d1b1",
   "metadata": {},
   "source": [
    "## Load All Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c156d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading raw CSV files...\n",
      "\n",
      "  ‚úì sales                (743268, 7)     ['Unnamed: 0', 'date', 'item_id', 'quantity', 'price_base', 'sum_total', 'store_id']\n",
      "  ‚úì price_history        (69863, 6)      ['Unnamed: 0', 'date', 'item_id', 'price', 'code', 'store_id']\n",
      "  ‚úì discounts_history    (374674, 9)     ['Unnamed: 0', 'date', 'item_id', 'sale_price_before_promo', 'sale_price_time_promo', 'promo_type_code', 'doc_id', 'number_disc_day', 'store_id']\n",
      "  ‚úì catalog              (21981, 9)      ['Unnamed: 0', 'item_id', 'dept_name', 'class_name', 'subclass_name', 'item_type', 'weight_volume', 'weight_netto', 'fatness']\n",
      "  ‚úì stores               (4, 5)          ['store_id', 'division', 'format', 'city', 'area']\n",
      "  ‚úì online               (112341, 7)     ['Unnamed: 0', 'date', 'item_id', 'quantity', 'price_base', 'sum_total', 'store_id']\n",
      "  ‚úì markdowns            (898, 7)        ['Unnamed: 0', 'date', 'item_id', 'normal_price', 'price', 'quantity', 'store_id']\n",
      "  ‚úì actual_matrix        (3520, 4)       ['Unnamed: 0', 'item_id', 'date', 'store_id']\n",
      "[OK] Total files loaded: 8\n"
     ]
    }
   ],
   "source": [
    "# Load all raw files using the pipeline function\n",
    "try:\n",
    "    dfs = load_raw_data('../data/raw')\n",
    "    print(f\"[OK] Total files loaded: {len(dfs)}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load raw data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b92c62",
   "metadata": {},
   "source": [
    "## Sales LONG format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a63ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã ACTUAL COLUMN NAMES IN EACH DATASET:\n",
      "\n",
      "SALES:\n",
      "  Columns: ['Unnamed: 0', 'date', 'item_id', 'quantity', 'price_base', 'sum_total', 'store_id']\n",
      "  Shape: (743268, 7)\n",
      "\n",
      "PRICE_HISTORY:\n",
      "  Columns: ['Unnamed: 0', 'date', 'item_id', 'price', 'code', 'store_id']\n",
      "  Shape: (69863, 6)\n",
      "\n",
      "DISCOUNTS_HISTORY:\n",
      "  Columns: ['Unnamed: 0', 'date', 'item_id', 'sale_price_before_promo', 'sale_price_time_promo', 'promo_type_code', 'doc_id', 'number_disc_day', 'store_id']\n",
      "  Shape: (374674, 9)\n",
      "\n",
      "CATALOG:\n",
      "  Columns: ['Unnamed: 0', 'item_id', 'dept_name', 'class_name', 'subclass_name', 'item_type', 'weight_volume', 'weight_netto', 'fatness']\n",
      "  Shape: (21981, 9)\n",
      "\n",
      "STORES:\n",
      "  Columns: ['store_id', 'division', 'format', 'city', 'area']\n",
      "  Shape: (4, 5)\n",
      "\n",
      "ONLINE:\n",
      "  Columns: ['Unnamed: 0', 'date', 'item_id', 'quantity', 'price_base', 'sum_total', 'store_id']\n",
      "  Shape: (112341, 7)\n",
      "\n",
      "MARKDOWNS:\n",
      "  Columns: ['Unnamed: 0', 'date', 'item_id', 'normal_price', 'price', 'quantity', 'store_id']\n",
      "  Shape: (898, 7)\n",
      "\n",
      "ACTUAL_MATRIX:\n",
      "  Columns: ['Unnamed: 0', 'item_id', 'date', 'store_id']\n",
      "  Shape: (3520, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check actual column names in each dataset\n",
    "print(\"üìã ACTUAL COLUMN NAMES IN EACH DATASET:\\n\")\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name.upper()}:\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970fca3b",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b97a764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä SAMPLE DATA:\n",
      "\n",
      "SALES (main transaction data):\n",
      "   Unnamed: 0        date       item_id  quantity  price_base  sum_total  \\\n",
      "0    16277163  2023-02-22  ef09dbc9fa66       2.0       44.91      89.82   \n",
      "1     1022837  2024-03-09  95416d766ab9       4.0       54.90     219.60   \n",
      "2    21699470  2024-09-19  65093e8d67e6       1.0      401.00     401.00   \n",
      "\n",
      "   store_id  \n",
      "0         2  \n",
      "1         1  \n",
      "2         4  \n",
      "\n",
      "STORES (store info):\n",
      "   store_id division    format   city  area\n",
      "0         4     Div1  MaxiEuro  City3  1887\n",
      "1         1     Div1   Regular  City1  1200\n",
      "2         2     Div2  MaxiEuro  City2  1500\n",
      "3         3     Div2   Regular  City4  1000\n"
     ]
    }
   ],
   "source": [
    "# Let's look at sample data from key files\n",
    "print(\"\\nüìä SAMPLE DATA:\\n\")\n",
    "print(\"SALES (main transaction data):\")\n",
    "print(dfs['sales'].head(3))\n",
    "print(\"\\nSTORES (store info):\")\n",
    "print(dfs['stores'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f7c32",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f81e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úì DATA FORMAT CHECK\n",
      "======================================================================\n",
      "Data is already in LONG FORMAT ‚úì\n",
      "  No need for pivot/melt operations\n",
      "  Each row = 1 transaction on 1 date\n",
      "  We can directly merge on (item_id, store_id, date)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ‚úì Data is ALREADY in long format (not wide format)\n",
    "# Each row = one transaction (date, item_id, store_id, quantity, price)\n",
    "# So we DON'T need to melt/pivot\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì DATA FORMAT CHECK\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Data is already in LONG FORMAT ‚úì\")\n",
    "print(f\"  No need for pivot/melt operations\")\n",
    "print(f\"  Each row = 1 transaction on 1 date\")\n",
    "print(f\"  We can directly merge on (item_id, store_id, date)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243a784",
   "metadata": {},
   "source": [
    "## Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40046da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ BUILDING MASTER DATASET FROM ALL 8 CSV FILES\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üîÑ Merging datasets...\n",
      "\n",
      "  1. Start with SALES as main table\n",
      "     Shape: (743268, 6)\n",
      "  2. Merge with STORES (on store_id)\n",
      "     Shape: (743268, 10)\n",
      "  3. Merge with CATALOG (on item_id)\n",
      "     Shape: (743268, 17)\n",
      "  4. Merge with PRICE_HISTORY (on item_id, store_id, date)\n",
      "     Shape: (743268, 19)\n",
      "  5. Merge with DISCOUNTS (aggregate on item_id, store_id, date)\n",
      "     Shape: (743268, 22)\n",
      "  6. Merge with ONLINE SALES (aggregate on item_id, store_id, date)\n",
      "     Shape: (743268, 25)\n",
      "  7. Merge with MARKDOWNS (aggregate on item_id, store_id, date)\n",
      "     Shape: (743268, 28)\n",
      "\n",
      "‚úì All merges complete!\n",
      "\n",
      "üìä Handling missing values...\n",
      "\n",
      "  Missing values before: 12899306\n",
      "  Missing values after:  0\n",
      "\n",
      "‚úÖ Master dataset built and saved!\n",
      "üìä Final dataset shape: (743268, 28)\n",
      "üìÅ Saved to: ../data/processed/final_dataset.csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Use the complete pipeline to build final dataset\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ BUILDING MASTER DATASET FROM ALL 8 CSV FILES\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "final_df = merge_datasets(dfs)\n",
    "final_df = handle_missing_values(final_df)\n",
    "\n",
    "# Save to processed folder\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "final_df.to_csv('../data/processed/final_dataset.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Master dataset built and saved!\")\n",
    "print(f\"üìä Final dataset shape: {final_df.shape}\")\n",
    "print(f\"üìÅ Saved to: ../data/processed/final_dataset.csv\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
